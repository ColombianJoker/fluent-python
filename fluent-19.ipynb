{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "639d20a7",
   "metadata": {},
   "source": [
    "# 19. Concurrency Models in Python\n",
    "\n",
    "> Concurrency is about dealing lots of things at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c524ac9",
   "metadata": {},
   "source": [
    "## Processes, Threads, and Python's Infamous GIL\n",
    "\n",
    "Here is how the concepts we just saw apply to Python programming, in 10 points:\n",
    "\n",
    "1. Each instance of the Python interpreter is a process. You can start additional Python processes using the _multiprocessing_ or _concurrent.futures_ libraries. Python’s _subprocess_ library is designed to launch processes to run external pro‐ grams, regardless of the languages used to write them.\n",
    "\n",
    "2. The Python interpreter uses a single thread to run the user’s program and the memory garbage collector. You can start additional Python threads using the _threading_ or _concurrent.futures_ libraries.\n",
    "\n",
    "3. Access to object reference counts and other internal interpreter state is con‐ trolled by a lock, the Global Interpreter Lock (GIL). Only one Python thread can hold the GIL at any time. This means that only one thread can execute Python code at any time, regardless of the number of CPU cores.\n",
    "\n",
    "4. To prevent a Python thread from holding the GIL indefinitely, Python’s bytecode interpreter pauses the current Python thread every 5ms by default,4 releasing the GIL. The thread can then try to reacquire the GIL, but if there are other threads waiting for it, the OS scheduler may pick one of them to proceed.\n",
    "\n",
    "5. When we write Python code, we have no control over the GIL. But a built-in function or an extension written in C—or any language that interfaces at the Python/C API level—can release the GIL while running time-consuming tasks.\n",
    "\n",
    "6. Every Python standard library function that makes a syscall releases the GIL. This includes all functions that perform disk I/O, network I/O, and `time.sleep()`. Many CPU-intensive functions in the NumPy/SciPy libraries, as well as the compressing/decompressing functions from the `zlib` and `bz2` modules, also release the GIL\n",
    "\n",
    "7. Extensions that integrate at the Python/C API level can also launch other non-Python threads that are not affected by the GIL. Such GIL-free threads generally cannot change Python objects, but they can read from and write to the memory underlying objects that support the buffer protocol, such as `bytearray`, `array.array`, and NumPy arrays.\n",
    "\n",
    "8. The effect of the GIL on network programming with Python threads is relatively small, because the I/O functions release the GIL, and reading or writing to the network always implies high latency—compared to reading and writing to memory. Consequently, each individual thread spends a lot of time waiting anyway, so their execution can be interleaved without major impact on the overall throughput. That’s why David Beazley says: “Python threads are great at doing nothing.”\n",
    "\n",
    "9. Contention over the GIL slows down compute-intensive Python threads. Sequential, single-threaded code is simpler and faster for such tasks.\n",
    "\n",
    "10. To run CPU-intensive Python code on multiple cores, you must use multiple Python processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03bdb72",
   "metadata": {},
   "source": [
    "## A Concurrent Hello World\n",
    "\n",
    "During a discussion about threads and how to avoid the GIL, Python contributor Michele Simionato posted an example that is like a concurrent “Hello World”: the simplest program to show how Python can “walk and chew gum.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef6d0b",
   "metadata": {},
   "source": [
    "### Spinner with Threads\n",
    "\n",
    "The idea of the next few examples is simple: start a function that blocks for 3 seconds while animating characters in the terminal to let the user know that the program is “thinking” and not stalled.\n",
    "\n",
    "The script makes an animated spinner displaying each character in the string \"\\|/-\" in the same screen position. When the slow computation finishes, the line with the spinner is cleared and the result is shown: Answer: 42."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b57a6",
   "metadata": {},
   "source": [
    "```python\n",
    "import itertools\n",
    "import time\n",
    "from threading import Thread, Event\n",
    "\n",
    "def spin(msg: str, done: Event) -> None:\n",
    "    for char in itertools.cycle(r'\\|/-'):\n",
    "        status = f'\\r{char} {msg}'\n",
    "        print(status, end='', flush=True)\n",
    "        if done.wait(.10):\n",
    "            break\n",
    "    blanks = ' '*len(status)\n",
    "    print(f'\\r{blanks}\\r', end='')\n",
    "\n",
    "def slow() -> int:\n",
    "    time.sleep(5)\n",
    "    return 42\n",
    "\n",
    "def supervisor() -> int:\n",
    "    done = Event()\n",
    "    spinner = Thread(target=spin, args=('thinking!', done))\n",
    "    print(f'spinner object: {spinner}')\n",
    "    spinner.start()\n",
    "    result = slow()\n",
    "    done.set()\n",
    "    spinner.join()\n",
    "    return result\n",
    "\n",
    "def main() -> None:\n",
    "    result = supervisor()\n",
    "    print(f'Answer: {result}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fcdb59",
   "metadata": {},
   "source": [
    "## Spinner with Processes\n",
    "\n",
    "The `multiprocessing` package supports running concurrent tasks in separate Python processes instead of threads. When you create a `multiprocessing.Process` instance, a whole new Python interpreter is started as a child process in the background. Since each Python process has its own GIL, this allows your program to use all available CPU cores—but that ultimately depends on the operating system scheduler.\n",
    "\n",
    "The point of this section is to introduce `multiprocessing` and show that its API emulates the `threading` API, making it easy to convert simple programs from threads to processes, as shown in `spinner_proc.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce3aa6",
   "metadata": {},
   "source": [
    "```python\n",
    "import itertools\n",
    "import time\n",
    "from multiprocessing import Process, Event\n",
    "from multiprocessing import synchronize\n",
    "\n",
    "def spin(msg: str, done: synchronize.Event) -> None:\n",
    "    for char in itertools.cycle(r'\\|/-'):\n",
    "        status = f'\\r{char} {msg}'\n",
    "        print(status, end='', flush=True)\n",
    "        if done.wait(.10):\n",
    "            break\n",
    "    blanks = ' '*len(status)\n",
    "    print(f'\\r{blanks}\\r', end='')\n",
    "\n",
    "def slow() -> int:\n",
    "    time.sleep(5)\n",
    "    return 42\n",
    "\n",
    "def supervisor() -> int:\n",
    "    done = Event()\n",
    "    spinner = Process(target=spin,\n",
    "                      args=('thinking!', done))\n",
    "    print(f'spinner object: {spinner}')\n",
    "    spinner.start()\n",
    "    result = slow()\n",
    "    done.set()\n",
    "    spinner.join()\n",
    "    return result\n",
    "\n",
    "def main() -> None:\n",
    "    result = supervisor()\n",
    "    print(f'Answer: {result}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6418c3",
   "metadata": {},
   "source": [
    "## Spinner with Coroutines\n",
    "\n",
    "It is the job of OS schedulers to allocate CPU time to drive threads and processes. In contrast, coroutines are driven by an application-level event loop that manages a queue of pending coroutines, drives them one by one, monitors events triggered by I/O operations initiated by coroutines, and passes control back to the corresponding coroutine when each event happens. The event loop and the library coroutines and the user coroutines all execute in a single thread. Therefore, any time spent in a coroutine slows down the event loop—and all other coroutines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5609ac4",
   "metadata": {},
   "source": [
    "`spinner_async.py` is shown:\n",
    "\n",
    "```python\n",
    "import time\n",
    "import asyncio\n",
    "import itertools\n",
    "\n",
    "async def spin(msg: str) -> None:\n",
    "    for char in itertools.cycle(r'\\|/-'):\n",
    "        status = f'\\r{char} {msg}'\n",
    "        print(status, flush=True, end='')\n",
    "        try:\n",
    "            await asyncio.sleep(.10)\n",
    "        except asyncio.CancelledError:\n",
    "            break\n",
    "    blanks = ' '*len(status)\n",
    "    print(f'\\r{blanks}\\r', end='')\n",
    "\n",
    "async def slow() -> int:\n",
    "    await asyncio.sleep(5)\n",
    "    return 42\n",
    "\n",
    "def main() -> None:\n",
    "    result = asyncio.run( supervisor() )\n",
    "    print(f'Answer: {result}')\n",
    "\n",
    "async def supervisor() -> int:\n",
    "    spinner = asyncio.create_task( spin('thinking!') )\n",
    "    print(f'spinner object: {spinner}')\n",
    "    result = await slow()\n",
    "    spinner.cancel()\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1562c",
   "metadata": {},
   "source": [
    "## The Real Impact of the GIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa866445",
   "metadata": {},
   "source": [
    "In the threading code, you cna replace the `time.sleep(3)` call in the `slow` function with an HTTP client request from your favorite library, and the spinner will keep spinning. That's because a well-designed network library will release the GIL while waiting for the network.\n",
    "\n",
    "You can also replace the `asyncio.sleep(3)` expression in the `slow` coroutine to `await` for a response from a well-designed asynchronous network library, because such libraries provide coroutines that yield control back to the event loop while waiting for the network. Meanwhile, the spinner will keep spinning.\n",
    "\n",
    "Whit CPU-intensive code, the story is different. Consider the function `is_prime` in example, which returns `True` if the argument is a prime number, `False` if it's not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08188f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def is_prime(n: int) -> bool:\n",
    "    if n<2:\n",
    "        return False\n",
    "    if n==2:\n",
    "        return True\n",
    "    if n%2==0:\n",
    "        return False\n",
    "    \n",
    "    root = math.isqrt(n)\n",
    "    for i in range(3, root+1, 2):\n",
    "        if n%i == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2beecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_prime(5_000_111_000_222_021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb42ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
