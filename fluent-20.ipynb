{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35f11186",
   "metadata": {},
   "source": [
    "# 20. Concurrent Executors\n",
    "\n",
    "> The people bashing threads are typically system programmers which have in mind use cases that the typical application programmer will never encounter in her life. [...] In 99% of the use cases an application programmer is likely to run into, the simple pat‐ tern of spawning a bunch of independent threads and collecting the results in a queue is everything one needs to know.\n",
    ">> Michele Simionato, Python deep thinker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c181f",
   "metadata": {},
   "source": [
    "## Concurrent Web Downloads\n",
    "\n",
    "Concurrency is essential for efficient network I/O: instead of idly waiting for remote machines, the application should do something else until a response comes back."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98cd4f9",
   "metadata": {},
   "source": [
    "### A Sequential Download Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee2eb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN \n",
      "20 downloads in 11.54s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import httpx\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP MX PH VN ET EG DE IR TR CD FR').split()\n",
    "\n",
    "BASE_URL = 'https://www.fluentpython.com/data/flags'\n",
    "DEST_DIR = Path('downloaded')\n",
    "\n",
    "def save_flag(img: bytes, filename: str) -> None:\n",
    "    (DEST_DIR / filename).write_bytes(img)\n",
    "\n",
    "def get_flag(cc: str) -> bytes:\n",
    "    url = f'{BASE_URL}/{cc}/{cc}.gif'.lower()\n",
    "    resp = httpx.get(url, timeout=6.1, follow_redirects=True)\n",
    "    resp.raise_for_status()\n",
    "    return resp.content\n",
    "\n",
    "def download_many(cc_list: list[str]) -> int:\n",
    "    for cc in sorted(cc_list):\n",
    "        image = get_flag(cc)\n",
    "        save_flag(image, f'{cc}.gif')\n",
    "        print(cc, end=' ', flush=True)\n",
    "    return len(cc_list)\n",
    "\n",
    "def main(downloader: Callable[list[str], int]) -> None:\n",
    "    DEST_DIR.mkdir(exist_ok=True)\n",
    "    t0 = time.perf_counter()\n",
    "    count = downloader(POP20_CC)\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    print(f'\\n{count} downloads in {elapsed:.2f}s')\n",
    "\n",
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4188ba60",
   "metadata": {},
   "source": [
    "### Downloading with `concurrent.futures`\n",
    "\n",
    "The main features of the `concurrent.futures` package are the `ThreadPoolExecutor` and `ProcessPoolExecutor` classes, which implement an API to submit callables for execution in different threads or processes, respectively. The classes transparently manage a pool of worker threads or processes, and queues to distribute jobs and collect results. But the interface is very high-level, and we don’t need to know about any of those details for a simple use case like our flag downloads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b438ffa",
   "metadata": {},
   "source": [
    "```python\n",
    "from concurrent import futures\n",
    "\n",
    "from flags import save_flag, get_flag, main\n",
    "\n",
    "def download_one(cc: str):\n",
    "    image = get_flag(cc)\n",
    "    save_flag(image, f'{cc}.gif')\n",
    "    print(cc, end=' ', flush=True)\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list: list[str]) -> int:\n",
    "    with futures.ThreadPoolExecutor() as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "\n",
    "    return len(list(res))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main(download_many)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33079f0",
   "metadata": {},
   "source": [
    "### Where Are the Futures?\n",
    "\n",
    "Futures are core components of `concurrent.futures` and of `asyncio`, but as users of these libraries we sometimes don’t see them. Example following depends on futures behind the scenes, but the code I wrote does not touch them directly. This section is an overview of futures, with an example that shows them in action.\n",
    "\n",
    "Since Python 3.4, there are two classes named Future in the standard library: `concurrent.futures.Future` and `asyncio.Future`. They serve the same purpose: an instance of either `Future` class represents a deferred computation that may or may not have completed. This is somewhat similar to the `Deferred` class in Twisted, the `Future` class in Tornado, and `Promise` in modern JavaScript.\n",
    "\n",
    "Futures encapsulate pending operations so that we can put them in queues, check whether they are done, and retrieve results (or exceptions) when they become available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69d2ef",
   "metadata": {},
   "source": [
    "## Launching Processes with `concurrent.futures`\n",
    "\n",
    "The `concurrent.futures` documentation page is subtitled “Launching parallel tasks.” The package enables parallel computation on multicore machines because it supports distributing work among multiple Python processes using the `ProcessPool Executor` class.\n",
    "\n",
    "Both `ProcessPoolExecutor` and `ThreadPoolExecutor` implement the `Executor` interface, so it’s easy to switch from a thread-based to a process-based solution using `concurrent.futures`.\n",
    "\n",
    "There is no advantage in using a `ProcessPoolExecutor` for the flags download example or any I/O-bound job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ecbed",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "from concurrent import futures\n",
    "\n",
    "from flags import save_flag, get_flag, main\n",
    "\n",
    "def download_one(cc: str):\n",
    "    image = get_flag(cc)\n",
    "    save_flag(image, f'{cc}.gif')\n",
    "    print(cc, end=' ', flush=True)\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list: list[str]) -> int:\n",
    "    # cc_list = cc_list[:5]\n",
    "    with futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        to_do: list[futures.Future] = []\n",
    "        for cc in sorted(cc_list):\n",
    "            future = executor.submit(download_one, cc)\n",
    "            to_do.append(future)\n",
    "            print(f'Scheduled for {cc}: {future}')\n",
    "        for count, future in enumerate(futures.as_completed(to_do), 1):\n",
    "            res: str = future.result()\n",
    "            print(f'{future} result: {res!r}')\n",
    "    return count\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main(download_many)\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb7ef9",
   "metadata": {},
   "source": [
    "The constructor for `ProcessPoolExecutor` also has a `max_workers` parameter, which defaults to `None`. In that case, the executor limits the number of workers to the number returned by `os.cpu_count()`.\n",
    "\n",
    "Processes use more memory and take longer to start than threads, so the real value of `ProcessPoolExecutor` is in CPU-intensive jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da562182",
   "metadata": {},
   "source": [
    "### Multicore Prime Cheker Redux\n",
    "\n",
    "In “Code for the Multicore Prime Checker” we studied `procs.py`, a script that checked the primality of some large numbers using `multiprocessing`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24290888",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys\n",
    "from concurrent import futures\n",
    "from time import perf_counter\n",
    "from typing import NamedTuple\n",
    "\n",
    "from primes import is_prime, NUMBERS\n",
    "\n",
    "class PrimeResult(NamedTuple):\n",
    "    n: int\n",
    "    flag: bool\n",
    "    elapsed: float\n",
    "\n",
    "def check(n: int) -> PrimeResult:\n",
    "    t0 = perf_counter()\n",
    "    res = is_prime(n)\n",
    "    return PrimeResult(n, res, perf_counter()-t0)\n",
    "\n",
    "def main() -> None:\n",
    "    if len(sys.argv) < 2:\n",
    "        workers = None\n",
    "    else:\n",
    "        workers = int(sys.argv[1])\n",
    "    \n",
    "    executor = futures.ProcessPoolExecutor(workers)\n",
    "    actual_workers = executor._max_workers\n",
    "\n",
    "    print(f'Checking {len(NUMBERS)} numbers with {actual_workers} processes:')\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    numbers = sorted(NUMBERS, reverse=True)\n",
    "    with executor:\n",
    "        for n, prime, elapsed in executor.map(check, numbers):\n",
    "            label = 'P' if prime else ' '\n",
    "            print(f'{n:16} {label} {elapsed:9.6f}s')\n",
    "\n",
    "    time = perf_counter() - t0\n",
    "    print(f'Total time: {time:.2f}s')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4800cf",
   "metadata": {},
   "source": [
    "## Experimenting with `Executor.map` \n",
    "\n",
    "Let’s investigate `Executor.map`, now using a `ThreadPoolExecutor` with three workers running five callables that output timestamped messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703a67a",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from time import sleep, strftime\n",
    "from concurrent import futures\n",
    "\n",
    "def display(*args):\n",
    "    print(strftime('[%H:%M:%S]'), end=' ')\n",
    "    print(*args)\n",
    "\n",
    "def loiter(n):\n",
    "    msg = '{}loiter({}): doing nothing for {}s...'\n",
    "    display(msg.format('\\t'*n, n, n))\n",
    "    sleep(n)\n",
    "    msg = '{}loiter({}): done.'\n",
    "    display(msg.format('\\t'*n, n))\n",
    "    return n*10\n",
    "\n",
    "def main():\n",
    "    display('Script starting.')\n",
    "    executor = futures.ThreadPoolExecutor(max_workers=3)\n",
    "    results = executor.map(loiter, range(8))\n",
    "    display('results:', results)\n",
    "    display('Waiting for individual results:')\n",
    "    for i, result in enumerate(results):\n",
    "        display(f'result {i}: {result}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a67a125",
   "metadata": {},
   "source": [
    "## Downloads with Progress Display and Error Handling\n",
    "\n",
    "As mentioned, the scripts in “Concurrent Web Downloads” have no error handling to make them easier to read and to contrast the structure of the three approaches: sequential, threaded, and asynchronous.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
